<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Conversation Companion</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            max-width: 600px;
            width: 100%;
            padding: 30px;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
            font-size: 28px;
        }

        .status {
            text-align: center;
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            font-weight: 500;
        }

        .status.listening {
            background: #e3f2fd;
            color: #1976d2;
        }

        .status.processing {
            background: #fff3e0;
            color: #f57c00;
        }

        .status.speaking {
            background: #f3e5f5;
            color: #7b1fa2;
        }

        .status.idle {
            background: #f5f5f5;
            color: #666;
        }

        .status.error {
            background: #ffebee;
            color: #c62828;
        }

        .button-group {
            display: flex;
            gap: 15px;
            margin-bottom: 30px;
        }

        button {
            flex: 1;
            padding: 15px 25px;
            border: none;
            border-radius: 10px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .start-btn {
            background: #4caf50;
            color: white;
        }

        .stop-btn {
            background: #f44336;
            color: white;
        }

        .message-box {
            background: #f9f9f9;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 20px;
            min-height: 100px;
            max-height: 300px;
            overflow-y: auto;
        }

        .message {
            margin-bottom: 15px;
            padding: 12px;
            border-radius: 8px;
        }

        .message.user {
            background: #e3f2fd;
            margin-left: 20%;
        }

        .message.assistant {
            background: #f1f8e9;
            margin-right: 20%;
        }

        .message-label {
            font-weight: 600;
            margin-bottom: 5px;
            font-size: 12px;
            text-transform: uppercase;
            opacity: 0.7;
        }

        .message-text {
            color: #333;
            line-height: 1.6;
        }

        .config {
            background: #f5f5f5;
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
        }

        .config input {
            width: 100%;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
            margin-top: 5px;
            font-size: 14px;
        }

        .config label {
            display: block;
            margin-bottom: 10px;
            font-weight: 500;
            color: #555;
        }

        .pulse {
            animation: pulse 1.5s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% {
                opacity: 1;
            }
            50% {
                opacity: 0.5;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è AI Conversation Companion</h1>
        
        <div class="config">
            <label>
                OpenAI API Key:
                <input type="password" id="apiKey" placeholder="sk-... or leave empty to use .env">
            </label>
        </div>

        <div id="status" class="status idle">Ready to start</div>

        <div class="button-group">
            <button id="startBtn" class="start-btn" onclick="startConversation()">Start Conversation</button>
            <button id="stopBtn" class="stop-btn" onclick="stopConversation()" disabled>Stop</button>
        </div>

        <div class="message-box" id="messages">
            <div style="text-align: center; color: #999; padding: 20px;">
                Conversation will appear here...
            </div>
        </div>
    </div>

    <script>
        let recognition = null;
        let isListening = false;
        let isAISpeaking = false;
        let conversationHistory = [];
        let apiKey = '';
        let currentAudio = null;

        // Initialize speech recognition
        function initSpeechRecognition() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'en-US';

                recognition.onstart = () => {
                    updateStatus('listening', 'üé§ Listening...');
                    isListening = true;
                };

                recognition.onresult = async (event) => {
                    // Don't process if AI is speaking
                    if (isAISpeaking) {
                        return;
                    }
                    
                    const transcript = event.results[0][0].transcript;
                    addMessage('user', transcript);
                    
                    // Stop listening while processing
                    recognition.stop();
                    await processUserInput(transcript);
                };

                recognition.onerror = (event) => {
                    console.error('Speech recognition error:', event.error);
                    updateStatus('error', `Error: ${event.error}`);
                    isListening = false;
                };

                recognition.onend = () => {
                    isListening = false;
                    // Only restart listening if session is active AND AI is not speaking
                    if (document.getElementById('startBtn').disabled && !isAISpeaking) {
                        setTimeout(() => {
                            if (document.getElementById('startBtn').disabled && !isAISpeaking) {
                                recognition.start();
                            }
                        }, 500);
                    } else if (!document.getElementById('startBtn').disabled) {
                        updateStatus('idle', 'Ready to start');
                    }
                };
            } else {
                alert('Speech recognition not supported in this browser. Please use Chrome or Edge.');
            }
        }

        // No need for browser TTS - using OpenAI TTS API instead

        // Get API key from input or server
        async function getApiKey() {
            const inputKey = document.getElementById('apiKey').value.trim();
            if (inputKey) {
                return inputKey;
            }

            // Try to load from server (which reads from .env)
            try {
                const response = await fetch('/api-key');
                if (response.ok) {
                    const data = await response.json();
                    if (data.apiKey) {
                        // Auto-fill the input field
                        document.getElementById('apiKey').value = data.apiKey;
                        return data.apiKey;
                    }
                }
            } catch (e) {
                console.log('Could not load API key from server');
            }

            // Return null - user should set it
            return null;
        }

        // Start conversation
        async function startConversation() {
            apiKey = await getApiKey();
            
            if (!apiKey) {
                alert('Please enter your OpenAI API key in the input field above, or create a .env file with OPENAI_API_KEY=your-key');
                return;
            }

            if (!recognition) {
                initSpeechRecognition();
            }

            document.getElementById('startBtn').disabled = true;
            document.getElementById('stopBtn').disabled = false;
            updateStatus('listening', 'Starting...');

            // Reset conversation
            conversationHistory = [
                {
                    role: 'system',
                    content: 'You are a friendly, helpful AI companion. Keep responses concise and conversational, suitable for voice interaction. Limit responses to 2-3 sentences.'
                }
            ];

            clearMessages();
            addMessage('system', 'Conversation started! Say something...');

            // Start listening
            try {
                recognition.start();
            } catch (e) {
                console.error('Error starting recognition:', e);
                updateStatus('error', 'Error starting speech recognition');
            }
        }

        // Stop conversation
        function stopConversation() {
            if (recognition) {
                recognition.stop();
            }
            
            // Stop any playing audio
            if (currentAudio) {
                currentAudio.pause();
                currentAudio = null;
            }

            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            isListening = false;
            isAISpeaking = false;
            updateStatus('idle', 'Stopped');
        }

        // Process user input and get AI response
        async function processUserInput(userText) {
            updateStatus('processing', 'ü§î Processing...');

            try {
                // Add user message to history
                conversationHistory.push({
                    role: 'user',
                    content: userText
                });

                // Call OpenAI API
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: JSON.stringify({
                        model: 'gpt-3.5-turbo',
                        messages: conversationHistory,
                        max_tokens: 150,
                        temperature: 0.7
                    })
                });

                if (!response.ok) {
                    const error = await response.json();
                    throw new Error(error.error?.message || 'API request failed');
                }

                const data = await response.json();
                const assistantMessage = data.choices[0].message.content;

                // Add assistant response to history
                conversationHistory.push({
                    role: 'assistant',
                    content: assistantMessage
                });

                // Display the response (it's already in conversationHistory)
                addMessage('assistant', assistantMessage);
                
                // Speak the response using OpenAI TTS
                await speakTextWithOpenAI(assistantMessage);

                // Keep history manageable
                if (conversationHistory.length > 20) {
                    conversationHistory = [
                        conversationHistory[0], // Keep system message
                        ...conversationHistory.slice(-18) // Keep last 18 messages
                    ];
                }

                // Resume listening after AI finishes speaking
                if (document.getElementById('startBtn').disabled) {
                    updateStatus('listening', 'üé§ Listening...');
                    setTimeout(() => {
                        if (recognition && document.getElementById('startBtn').disabled && !isAISpeaking) {
                            recognition.start();
                        }
                    }, 500);
                }

            } catch (error) {
                console.error('Error processing input:', error);
                updateStatus('error', `Error: ${error.message}`);
                addMessage('system', `Error: ${error.message}`);
            }
        }

        // Speak text using OpenAI TTS API (much better quality)
        async function speakTextWithOpenAI(text) {
            if (!apiKey) {
                console.warn('No API key for TTS');
                return;
            }

            // Set AI speaking flag early to prevent recognition
            isAISpeaking = true;
            
            // Keep "Processing" status while generating audio
            updateStatus('processing', 'üéµ Generating audio...');

            try {
                // Stop any current recognition
                if (recognition && isListening) {
                    recognition.stop();
                }

                // Call OpenAI TTS API
                const response = await fetch('https://api.openai.com/v1/audio/speech', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: JSON.stringify({
                        model: 'tts-1', // High quality voice model
                        voice: 'alloy', // Natural sounding voice (options: alloy, echo, fable, onyx, nova, shimmer)
                        input: text,
                        speed: 1.0
                    })
                });

                if (!response.ok) {
                    const error = await response.json();
                    throw new Error(error.error?.message || 'TTS API request failed');
                }

                // Get audio blob
                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                
                // Stop any currently playing audio
                if (currentAudio) {
                    currentAudio.pause();
                    currentAudio = null;
                }

                currentAudio = new Audio(audioUrl);
                
                // Wait for audio to finish playing
                await new Promise((resolve, reject) => {
                    // Only show "AI is speaking" when audio actually starts playing
                    currentAudio.onplay = () => {
                        updateStatus('speaking', 'üîä AI is speaking...');
                    };
                    
                    currentAudio.onended = () => {
                        URL.revokeObjectURL(audioUrl);
                        currentAudio = null;
                        resolve();
                    };
                    currentAudio.onerror = (error) => {
                        URL.revokeObjectURL(audioUrl);
                        currentAudio = null;
                        reject(error);
                    };
                    
                    // Start playing - onplay will fire when it actually starts
                    currentAudio.play().catch(reject);
                });

            } catch (error) {
                console.error('Error with TTS:', error);
                updateStatus('error', `TTS Error: ${error.message}`);
                isAISpeaking = false;
            } finally {
                // Clear AI speaking flag
                isAISpeaking = false;
            }
        }

        // Add message to UI
        function addMessage(role, text) {
            const messagesDiv = document.getElementById('messages');
            
            // Clear placeholder if exists
            if (messagesDiv.children.length === 1 && messagesDiv.children[0].textContent.includes('Conversation')) {
                messagesDiv.innerHTML = '';
            }

            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;
            
            const labelDiv = document.createElement('div');
            labelDiv.className = 'message-label';
            labelDiv.textContent = role === 'user' ? 'üë§ You' : role === 'assistant' ? 'ü§ñ Assistant' : '‚ÑπÔ∏è System';
            
            const textDiv = document.createElement('div');
            textDiv.className = 'message-text';
            textDiv.textContent = text;
            
            messageDiv.appendChild(labelDiv);
            messageDiv.appendChild(textDiv);
            messagesDiv.appendChild(messageDiv);
            
            // Scroll to bottom
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }

        // Clear messages
        function clearMessages() {
            document.getElementById('messages').innerHTML = '';
        }

        // Update status
        function updateStatus(type, message) {
            const statusDiv = document.getElementById('status');
            statusDiv.className = `status ${type}`;
            statusDiv.textContent = message;
            
            if (type === 'listening') {
                statusDiv.classList.add('pulse');
            } else {
                statusDiv.classList.remove('pulse');
            }
        }

        // Initialize on page load
        window.addEventListener('load', async () => {
            // Check for API key in URL params (for quick testing)
            const urlParams = new URLSearchParams(window.location.search);
            const keyParam = urlParams.get('key');
            if (keyParam) {
                document.getElementById('apiKey').value = keyParam;
            } else {
                // Try to load from server (.env file)
                try {
                    const response = await fetch('/api-key');
                    if (response.ok) {
                        const data = await response.json();
                        if (data.apiKey) {
                            document.getElementById('apiKey').value = data.apiKey;
                        }
                    }
                } catch (e) {
                    // Server not running or no .env file - that's okay
                    console.log('Running standalone - enter API key manually');
                }
            }
        });
    </script>
</body>
</html>

