<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TICS-m Assessment</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            max-width: 800px;
            width: 100%;
            padding: 30px;
        }

        .header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 30px;
        }

        h1 {
            text-align: left;
            color: #333;
            font-size: 28px;
            margin: 0;
        }

        .nav-buttons {
            display: flex;
            gap: 10px;
        }

        .nav-btn {
            padding: 10px 20px;
            background: #2196f3;
            color: white;
            text-decoration: none;
            border-radius: 8px;
            font-weight: 600;
            font-size: 14px;
        }

        .status {
            text-align: center;
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            font-weight: 500;
        }

        .status.listening {
            background: #e3f2fd;
            color: #1976d2;
        }

        .status.processing {
            background: #fff3e0;
            color: #f57c00;
        }

        .status.speaking {
            background: #f3e5f5;
            color: #7b1fa2;
        }

        .status.idle {
            background: #f5f5f5;
            color: #666;
        }

        .status.countdown {
            background: #fff9c4;
            color: #f57f17;
            font-size: 24px;
            font-weight: bold;
        }

        .status.error {
            background: #ffebee;
            color: #c62828;
        }

        .status.scoring {
            background: #e8f5e9;
            color: #2e7d32;
        }

        .button-group {
            display: flex;
            gap: 15px;
            margin-bottom: 30px;
        }

        button {
            flex: 1;
            padding: 15px 25px;
            border: none;
            border-radius: 10px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .start-btn {
            background: #4caf50;
            color: white;
        }

        .stop-btn {
            background: #f44336;
            color: white;
        }

        .message-box {
            background: #f9f9f9;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 20px;
            min-height: 150px;
            max-height: 400px;
            overflow-y: auto;
        }

        .message {
            margin-bottom: 15px;
            padding: 12px;
            border-radius: 8px;
        }

        .message.user {
            background: #e3f2fd;
            margin-left: 20%;
        }

        .message.assistant {
            background: #f1f8e9;
            margin-right: 20%;
        }

        .message-label {
            font-weight: 600;
            margin-bottom: 5px;
            font-size: 12px;
            text-transform: uppercase;
            opacity: 0.7;
        }

        .message-text {
            color: #333;
            line-height: 1.6;
        }

        .config {
            background: #f5f5f5;
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
        }

        .config input {
            width: 100%;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
            margin-top: 5px;
            font-size: 14px;
        }

        .config label {
            display: block;
            margin-bottom: 10px;
            font-weight: 500;
            color: #555;
        }

        .pulse {
            animation: pulse 1.5s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% {
                opacity: 1;
            }
            50% {
                opacity: 0.5;
            }
        }

        /* Results Section */
        .results-section {
            display: none;
            margin-top: 30px;
        }

        .results-section.active {
            display: block;
        }

        .results-header {
            text-align: center;
            margin-bottom: 30px;
        }

        .results-header h2 {
            color: #333;
            font-size: 24px;
            margin-bottom: 10px;
        }

        .score-card {
            background: #f9f9f9;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 15px;
        }

        .score-card-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            cursor: pointer;
            user-select: none;
        }

        .score-card-header h3 {
            color: #333;
            font-size: 18px;
            margin: 0;
        }

        .score-badge {
            padding: 5px 15px;
            border-radius: 20px;
            font-weight: 600;
            font-size: 14px;
        }

        .score-badge.correct {
            background: #4caf50;
            color: white;
        }

        .score-badge.incorrect {
            background: #f44336;
            color: white;
        }

        .score-badge.partial {
            background: #ff9800;
            color: white;
        }

        .score-explanation {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease-out;
            margin-top: 15px;
            padding-top: 15px;
            border-top: 1px solid #ddd;
        }

        .score-explanation.expanded {
            max-height: 500px;
        }

        .score-explanation-content {
            color: #555;
            line-height: 1.6;
        }

        .loading-spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid #f3f3f3;
            border-top: 3px solid #667eea;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin-right: 10px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .summary-stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin-bottom: 30px;
        }

        .summary-stat {
            background: white;
            border-radius: 10px;
            padding: 20px;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        .summary-stat-label {
            font-size: 12px;
            color: #666;
            text-transform: uppercase;
            margin-bottom: 8px;
        }

        .summary-stat-value {
            font-size: 32px;
            font-weight: bold;
            color: #667eea;
        }

        .pipeline-nav {
            text-align: center;
            margin-top: 40px;
            padding-top: 30px;
            border-top: 2px solid #e0e0e0;
        }

        .pipeline-step {
            font-size: 14px;
            color: #666;
            margin-bottom: 20px;
            font-weight: 500;
        }

        .next-arrow {
            display: inline-flex;
            flex-direction: column;
            align-items: center;
            text-decoration: none;
            color: #667eea;
            transition: all 0.3s;
            padding: 15px 30px;
            border-radius: 12px;
            background: #f5f5ff;
            border: 2px solid #667eea;
        }

        .next-arrow:hover {
            background: #667eea;
            color: white;
            transform: translateY(-3px);
            box-shadow: 0 5px 20px rgba(102, 126, 234, 0.4);
        }

        .next-arrow-icon {
            font-size: 36px;
            animation: arrowPulse 2s ease-in-out infinite;
            display: block;
            margin-bottom: 8px;
        }

        @keyframes arrowPulse {
            0%, 100% {
                transform: translateX(0);
            }
            50% {
                transform: translateX(8px);
            }
        }

        .next-arrow-text {
            font-size: 16px;
            font-weight: 600;
            display: block;
        }

        .nav-links {
            position: fixed;
            top: 20px;
            right: 20px;
            display: flex;
            gap: 10px;
            z-index: 1000;
        }

        .dashboard-link {
            padding: 12px 24px;
            background: #2196f3;
            color: white;
            text-decoration: none;
            border-radius: 10px;
            font-weight: 600;
            font-size: 14px;
            box-shadow: 0 3px 12px rgba(0,0,0,0.2);
            transition: all 0.3s;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .dashboard-link:hover {
            background: #1976d2;
            transform: translateY(-2px);
            box-shadow: 0 5px 18px rgba(0,0,0,0.3);
        }

        .audio-player {
            margin-top: 20px;
            text-align: center;
            background: #f9f9f9;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 20px;
        }

        .audio-player audio {
            width: 100%;
            max-width: 500px;
        }

        .voice-analysis-results {
            display: none;
            background: #f9f9f9;
            border-radius: 10px;
            padding: 25px;
            margin-top: 30px;
        }

        .voice-analysis-results.active {
            display: block;
        }

        .voice-analysis-results h2 {
            color: #333;
            margin-bottom: 20px;
            font-size: 22px;
        }

        .result-item {
            background: white;
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 15px;
            border-left: 4px solid #667eea;
        }

        .result-label {
            font-weight: 600;
            color: #666;
            margin-bottom: 5px;
            font-size: 14px;
            text-transform: uppercase;
        }

        .result-value {
            font-size: 24px;
            font-weight: bold;
            color: #333;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .result-icon {
            font-size: 32px;
        }

        .result-icon.healthy {
            color: #4caf50;
        }

        .result-icon.mci {
            color: #ff9800;
        }

        .description-modal {
            background: #f0f7ff;
            border-left: 4px solid #2196f3;
            border-radius: 8px;
            padding: 15px;
            margin: 15px 0;
            font-size: 14px;
            color: #333;
            line-height: 1.6;
        }

        .description-modal h4 {
            margin: 0 0 8px 0;
            color: #1976d2;
            font-size: 16px;
        }

        .result-probabilities {
            margin-top: 15px;
            padding-top: 15px;
            border-top: 1px solid #e0e0e0;
        }

        .probability-bar-container {
            margin-bottom: 20px;
        }

        .probability-bar-label {
            display: flex;
            justify-content: space-between;
            margin-bottom: 8px;
            font-size: 14px;
            font-weight: 500;
            color: #666;
        }

        .probability-bar-wrapper {
            width: 100%;
            height: 30px;
            background: #e0e0e0;
            border-radius: 15px;
            overflow: hidden;
            position: relative;
        }

        .probability-bar {
            height: 100%;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            border-radius: 15px;
            transition: width 1s ease-out;
            display: flex;
            align-items: center;
            justify-content: flex-end;
            padding-right: 10px;
            color: white;
            font-weight: 600;
            font-size: 12px;
            animation: barLoad 1s ease-out;
        }

        .probability-bar.healthy {
            background: linear-gradient(90deg, #4caf50 0%, #66bb6a 100%);
        }

        .probability-bar.mci {
            background: linear-gradient(90deg, #ff9800 0%, #ffb74d 100%);
        }

        @keyframes barLoad {
            0% {
                width: 0% !important;
            }
        }
    </style>
</head>
<body>
    <div class="nav-links">
        <a href="/" class="dashboard-link">üè† Home</a>
        <a href="/dashboard" class="dashboard-link">üìä View Dashboard</a>
    </div>
    
    <div class="container">
        <div style="text-align: center; margin-bottom: 30px;">
            <div style="font-size: 12px; color: #666; margin-bottom: 10px; text-transform: uppercase; letter-spacing: 1px;">Step 2 of 3</div>
            <h1 style="margin: 0;">üß† Cognitive Assessment</h1>
            <p style="color: #666; margin-top: 10px; font-size: 16px;">We'll ask you a few simple questions. Please answer naturally and take your time.</p>
        </div>
        
        <div class="config">
            <label>
                AI Language:
                <div style="margin-top: 5px;">
                    <button id="languageToggle" onclick="toggleLanguage()" style="padding: 8px 16px; font-size: 14px; background: #667eea; color: white; border: none; border-radius: 5px; cursor: pointer; font-weight: 600;">
                        <span id="languageLabel">English</span> <span id="languageFlag">üá∫üá∏</span>
                    </button>
                </div>
            </label>
            <label style="margin-top: 15px;">
                <input type="password" id="apiKey" placeholder="sk-... or leave empty to use .env">
            </label>
        </div>

        <div id="status" class="status idle">Ready to begin your assessment</div>

        <div class="button-group">
            <button id="startBtn" class="start-btn" onclick="startAssessment()">Begin Assessment</button>
            <button id="stopBtn" class="stop-btn" onclick="stopAssessment()" disabled>Complete Assessment</button>
        </div>

        <div class="message-box" id="messages">
            <div style="text-align: center; color: #999; padding: 20px;">
                Your assessment will appear here once you begin...
            </div>
        </div>

        <div class="audio-player" id="audioPlayer" style="display: none;">
            <p style="margin-bottom: 10px; color: #666;">Recorded Audio:</p>
            <audio id="audioPlayback" controls></audio>
        </div>

        <div class="pipeline-nav">
            <div class="pipeline-step">When you're ready, continue to the next step</div>
            <a href="/audio_test" class="next-arrow">
                <span class="next-arrow-icon">‚Üí</span>
                <span class="next-arrow-text">Voice Analysis</span>
            </a>
        </div>

        <div id="resultsSection" class="results-section">
            <div class="results-header">
                <h2>Assessment Results</h2>
                <div class="loading-spinner" id="scoringSpinner" style="display: none;"></div>
                <p id="scoringStatus" style="color: #666; margin-top: 10px;"></p>
            </div>

            <div id="summaryStats" class="summary-stats"></div>

            <div id="scoreCards"></div>
        </div>

        <div class="voice-analysis-results" id="voiceAnalysisResults">
            <h2>Voice Analysis Results</h2>
            <div class="result-item">
                <div class="result-label">Voice Analysis Result</div>
                <div class="result-value" id="predictedClass">-</div>
            </div>
            <div class="description-modal" id="descriptionModal" style="display: none;">
                <h4 id="descriptionTitle"></h4>
                <p id="descriptionText"></p>
            </div>
            <div class="result-item" id="probabilitiesSection" style="display: none;">
                <div class="result-label">Detailed Probabilities</div>
                <div class="result-probabilities" id="probabilities"></div>
            </div>
        </div>
    </div>

    <script>
        let peerConnection = null;
        let audioElement = null;
        let dataChannel = null;
        let userAudioTrack = null;
        let userStream = null;
        let isSessionActive = false;
        let messageText = '';
        let conversationHistory = [];
        let currentCountdown = null;
        let audioBlob = null;
        let mediaRecorder = null;
        let isRecording = false;
        let audioSegments = []; // Array to store audio segments from each listening period
        let currentSegmentChunks = []; // Chunks for current segment
        const API_ENDPOINT = 'http://localhost:5001/analyze';
        let currentLanguage = 'en'; // 'en' for English, 'zh' for Chinese

        // Get API key from input or server
        async function getApiKey() {
            const inputKey = document.getElementById('apiKey').value.trim();
            if (inputKey) {
                return inputKey;
            }

            try {
                const response = await fetch('/api-key');
                if (response.ok) {
                    const data = await response.json();
                    if (data.apiKey) {
                        document.getElementById('apiKey').value = data.apiKey;
                        return data.apiKey;
                    }
                }
            } catch (e) {
                console.log('Could not load API key from server');
            }

            return null;
        }

        // Get ephemeral key for Realtime API
        async function getEphemeralKey(apiKey) {
            try {
                const response = await fetch('/token');
                if (response.ok) {
                    const data = await response.json();
                    return data.client_secret?.value || data.clientSecret?.value;
                }
            } catch (e) {
                console.log('Server token endpoint not available, using API key directly');
            }
            
            return apiKey;
        }

        // Countdown function
        async function showCountdown(callback) {
            return new Promise((resolve) => {
                let count = 3;
                updateStatus('countdown', count.toString());
                
                const countdownInterval = setInterval(() => {
                    count--;
                    if (count > 0) {
                        updateStatus('countdown', count.toString());
                    } else {
                        clearInterval(countdownInterval);
                        updateStatus('listening', 'üé§ Listening...');
                        if (callback) callback();
                        resolve();
                    }
                }, 1000);
            });
        }

        // Start assessment
        async function startAssessment() {
            const apiKey = await getApiKey();
            
            if (!apiKey) {
                alert('Please enter your OpenAI API key in the input field above, or create a .env file with OPENAI_API_KEY=your-key');
                return;
            }

            try {
                updateStatus('processing', 'üîÑ Connecting...');
                
                const ephemeralKey = await getEphemeralKey(apiKey);
                if (!ephemeralKey) {
                    throw new Error('Could not get ephemeral key');
                }

                // Reset conversation history
                conversationHistory = [];
                audioSegments = [];
                currentSegmentChunks = [];
                isRecording = false;
                
                // Create peer connection
                peerConnection = new RTCPeerConnection();

                // Create audio element for server audio
                audioElement = document.createElement('audio');
                audioElement.autoplay = true;
                audioElement.muted = false;
                document.body.appendChild(audioElement);

                // Handle incoming server audio
                peerConnection.ontrack = (event) => {
                    if (event.track.kind === 'audio' && event.streams && event.streams[0]) {
                        audioElement.srcObject = event.streams[0];
                        audioElement.play().catch(e => {
                            console.error('Audio play failed:', e);
                        });
                        updateStatus('speaking', 'üîä AI is speaking...');
                    }
                };

                // Create data channel for events
                dataChannel = peerConnection.createDataChannel('oai-events', { ordered: true });
                
                dataChannel.onopen = () => {
                    console.log('Data channel opened');
                    isSessionActive = true;
                    
                    // Build session configuration with TICS-m script
                    const todayDate = new Date().toLocaleDateString('en-US', { weekday: 'long', month: 'long', day: 'numeric', year: 'numeric' });
                    
                    // Get instructions based on language
                    let instructions;
                    if (currentLanguage === 'zh') {
    instructions = `‰Ω†Ê≠£Âú®ËøõË°å‰∏ÄÊ¨° TICS-mÔºà‰øÆËÆ¢ÁâàÁîµËØùËÆ§Áü•Áä∂ÊÄÅËÆøË∞àÔºâËØÑ‰º∞„ÄÇËØ∑‰∏•Ê†ºÊåâÁÖß‰ª•‰∏ãËÑöÊú¨ÊâßË°åÔºåÂπ∂ÈÅµÂÆà‰ª•‰∏ãËßÑÂàôÔºö

„ÄêÈáçË¶ÅËßÑÂàô„Äë
- 1) ‰∏çË¶ÅÂëäËØâÁî®Êà∑‰ªñ‰ª¨ÁöÑÂõûÁ≠îÊòØ‚ÄúÊ≠£Á°Æ/ÈîôËØØ‚ÄùÔºà‰∏çË¶ÅËØÑ‰ª∑ÂØπÈîôÔºâ„ÄÇ
- 2) Èô§‰∫Ü‚Äú‰ªäÂ§©ÊòØÂá†Âè∑Ôºü‚ÄùËøô‰∏ÄÈ¢ò‰ª•Â§ñÔºöÂè™Ë¶ÅÂØπÊñπÁöÑÂõûÁ≠îÂê¨ÂæóÊ∏ÖÊ•ö„ÄÅ‰∏î‰∏éÈóÆÈ¢òÊúâ‰∏ÄÂÆöÂÖ≥ËÅîÔºàÂç≥‰ΩøÂÜÖÂÆπ‰∏çÊ≠£Á°ÆÔºå‰æãÂ¶ÇÊääËØç/Êï∞Â≠óÈ°∫Â∫èËØ¥Èîô„ÄÅËØ¥ÊàêÂà´ÁöÑËØçÁ≠âÔºâÔºåÈÉΩ‰∏çË¶ÅËøΩÈóÆÔºåÁõ¥Êé•ËøõÂÖ•‰∏ã‰∏ÄÈ¢ò„ÄÇ
- 3) Âè™ÊúâÂú®ÂõûÁ≠îÂÆåÂÖ®Êó†Ê≥ïÁêÜËß£Êàñ‰∏éÈóÆÈ¢òÊØ´Êó†ÂÖ≥ËÅîÊó∂ÊâçËØ∑ÂØπÊñπÈáçÂ§çÔºà‰æãÂ¶ÇÔºöÈïøÊó∂Èó¥Ê≤âÈªò„ÄÅÂê¨‰∏çÊ∏Ö„ÄÅËÉ°‰π±Âô™Èü≥„ÄÅÂÆåÂÖ®‰∏çÁõ∏ÂÖ≥ÁöÑÈöèÊú∫ËØç‰∏îÊó†Ê≥ïÂà§Êñ≠ÊòØÂú®ÂõûÁ≠î‰ªÄ‰πàÔºâ„ÄÇ

È¶ñÂÖàËØ¥Ôºö
"È¶ñÂÖàÔºåÈóÆÊÇ®Âá†‰∏™ÁÆÄÁü≠ÁöÑÈóÆÈ¢ò„ÄÇ"

ÂÆöÂêëÂäõÈóÆÈ¢òÔºàÊØè‰∏™ÈóÆÈ¢òÂêéÈÉΩË¶ÅÁ≠âÂæÖÂØπÊñπÂõûÁ≠îÔºâÔºö

"‰ªäÂ§©ÊòØÂá†Âè∑Ôºü"
ÔºàÊ≠£Á°ÆÁ≠îÊ°àÂ∫î‰∏éÔºö${todayDate} ‰∏ÄËá¥Ôºâ„ÄÇ
Â¶ÇÊûú‰ªñ‰ª¨Âè™ËØ¥‰∫ÜÊó•ÊúüÁöÑ‰∏ÄÈÉ®ÂàÜÔºà‰æãÂ¶ÇÂè™ËØ¥ÊòüÊúüÔºåÊàñÂè™ËØ¥Êó•Êúü + Êúà‰ªΩÔºâÔºåËØ∑ÊèêÁ§∫‰ªñ‰ª¨Ë°•ÂÖÖÁº∫Â§±ÁöÑÈÉ®ÂàÜÂêéÂÜçÁªßÁª≠„ÄÇ
Ê≥®ÊÑèÔºöËøôÈáåÂèØ‰ª•ÊèêÁ§∫‰ªñ‰ª¨Ë°•ÂÖ®Âπ¥‰ªΩ/Êúà‰ªΩ/Êó•ÊúüÔºå‰ΩÜ‰ªç‰∏çË¶ÅËØ¥‰ªñ‰ª¨‚ÄúÂØπ/Èîô‚Äù„ÄÇ

"Êàë‰ª¨Áé∞Âú®ÊâÄÂú®ÁöÑÂüéÂ∏ÇÊòØÂì™ÈáåÔºü"
ÔºàÊ≠£Á°ÆÁ≠îÊ°àÊòØÔºöÊñ∞Âä†Âù°Ôºâ

Ê≥®ÊÑèÂäõÈóÆÈ¢òÔºàÊØè‰∏™ÈóÆÈ¢òÂêéÈÉΩË¶ÅÁ≠âÂæÖÂØπÊñπÂõûÁ≠îÔºâÔºö

"ÊàëÂ∞ÜËØ¥Âá†‰∏™Êï∞Â≠óÔºåËØ∑ÊÇ®ÈáçÂ§ç‰∏ÄÈÅçÔºö8‚Äì1‚Äì4„ÄÇ"
ÔºàÊ≠£Á°ÆÁ≠îÊ°àÔºö8Ôºå1Ôºå4Ôºâ

"Áé∞Âú®ËØ∑ÊÇ®ÊääËøô‰∫õÊï∞Â≠óÂÄíÁùÄËØ¥‰∏ÄÈÅçÔºö6‚Äì2‚Äì9„ÄÇ"
ÔºàÊ≠£Á°ÆÁ≠îÊ°àÔºö9Ôºå2Ôºå6Ôºâ

Âç≥Êó∂ÂõûÂøÜÔºö

"ÊàëÂ∞ÜËØ¥‰∏â‰∏™ËØçÔºåËØ∑ÊÇ®Áé∞Âú®ÈáçÂ§ç‰∏ÄÈÅçÔºöÊ≤≥ÊµÅÔºåÊ§ÖÂ≠êÔºåËäíÊûú„ÄÇ"
ÔºàÁ≠âÂæÖ‰ªñ‰ª¨ÈáçÂ§çÂÖ®ÈÉ®‰∏â‰∏™ËØçÔºâ

Âú®ÊØè‰∏™ÈóÆÈ¢ò‰πãÂêéÔºåËØ∑Á≠âÂæÖÁî®Êà∑ÁªôÂá∫ÂÆåÊï¥ÂõûÁ≠îÂêéÂÜçÁªßÁª≠„ÄÇ
‰øùÊåÅËÄêÂøÉÂíåÂèãÂ•ΩÁöÑÊÄÅÂ∫¶„ÄÇ
‰Ω†ÁöÑÂõûÂ∫îË¶ÅÁÆÄÁü≠ÔºåÂè™ÈúÄ‰∏≠ÊÄßÁ°ÆËÆ§Ôºà‰æãÂ¶Ç‚ÄúÂ•ΩÁöÑ/ÊòéÁôΩ‰∫Ü/Ë∞¢Ë∞¢‚ÄùÔºâÁÑ∂ÂêéËøõÂÖ•‰∏ã‰∏ÄÈ¢ò„ÄÇ
Â¶ÇÊûú‰ªñ‰ª¨ÁöÑÂõûÁ≠îÂê¨‰∏çÊ∏ÖÊàñÊó†Ê≥ïÁêÜËß£ÔºåÊâçËØ∑‰ªñ‰ª¨ÈáçÂ§ç‰∏ÄÈÅçÁ≠îÊ°à„ÄÇ`;
} else {
    instructions = `You are conducting a TICS-m (Telephone Interview for Cognitive Status-modified) assessment. Follow this script exactly, and obey these rules:

IMPORTANT RULES
- 1) Do NOT tell the user whether they are correct or incorrect (no correctness feedback).
- 2) For EVERYTHING except the "What is today's date?" question: if the answer is intelligible and appears to be an attempt related to the question (even if wrong, e.g., wrong order like "dog, mango, river" or saying the digits incorrectly), do NOT ask again‚Äîacknowledge neutrally and move on.
- 3) Only ask them to repeat if the response is completely unintelligible or clearly unrelated to the question (e.g., silence, inaudible audio, gibberish/noise, random words with no connection).

1. First say: "First, a few quick questions."

2. Orientation questions (wait for response after each):
   - "What is today's date?" (The correct answer should match: ${todayDate}). If they say only part of the date (ie Day, Day + Month) urge them to complete the missing component before moving on.
     Note: You may prompt for missing components here (e.g., ask for the year), but still do not say whether they are correct/incorrect.
   - "What city are we in right now?" (The correct answer is: Singapore)

3. Attention questions (wait for response after each):
   - "I'm going to say some digits. Please repeat them back to me: 8‚Äì1‚Äì4." (Correct: 8, 1, 4)
   - "Now repeat these backwards: 6‚Äì2‚Äì9." (Correct: 9, 2, 6 backwards)

4. Immediate recall:
   - "I'll say three words. Please repeat them now: river, chair, mango." (Wait for them to repeat all three words)

After each question, wait for the user's complete response before proceeding. Be patient and friendly. Keep your responses brief, use neutral acknowledgements (e.g., "Okay," "Thanks," "I see"), then move to the next question. If they say something unintelligible or unrelated, ask them to repeat.`;
}

                    
                    const sessionConfig = {
                        modalities: ['text', 'audio'],
                        instructions: instructions,
                        input_audio_transcription: {
                            model: 'whisper-1'
                        },
                        turn_detection: {
                            type: 'server_vad',
                            threshold: 0.5,
                            prefix_padding_ms: 300,
                            silence_duration_ms: 2000
                        }
                    };
                    
                    // Send session configuration
                    const event = {
                        type: 'session.update',
                        session: sessionConfig
                    };
                    dataChannel.send(JSON.stringify(event));
                    
                    updateStatus('speaking', 'üîä AI is speaking...');
                };

                dataChannel.onmessage = (event) => {
                    const message = JSON.parse(event.data);
                    handleMessage(message);
                };

                // Get user microphone
                userStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                userAudioTrack = userStream.getAudioTracks()[0];
                peerConnection.addTrack(userAudioTrack, userStream);
                userAudioTrack.enabled = true;

                // MediaRecorder will be started/stopped based on listening state
                // Don't start recording yet - wait for listening state

                // Create offer
                const offer = await peerConnection.createOffer();
                await peerConnection.setLocalDescription(offer);

                // Send offer to OpenAI Realtime API
                const sdpRes = await fetch('https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17', {
                    method: 'POST',
                    body: offer.sdp,
                    headers: {
                        'Authorization': `Bearer ${ephemeralKey}`,
                        'Content-Type': 'application/sdp'
                    }
                });

                if (!sdpRes.ok) {
                    const errorText = await sdpRes.text();
                    throw new Error(`SDP exchange failed: ${sdpRes.status} - ${errorText}`);
                }

                // Set remote answer
                const answerSdp = await sdpRes.text();
                await peerConnection.setRemoteDescription({ type: 'answer', sdp: answerSdp });

                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                document.getElementById('languageToggle').disabled = true;
                clearMessages();
                addMessage('system', 'Assessment started. Please listen carefully and answer each question naturally.');

            } catch (error) {
                console.error('Error starting assessment:', error);
                updateStatus('error', `Error: ${error.message}`);
                stopAssessment();
            }
        }

        // Start recording user audio segment (during listening state)
        function startRecordingSegment() {
            if (!userStream || isRecording) {
                return;
            }

            try {
                currentSegmentChunks = [];
                mediaRecorder = new MediaRecorder(userStream);
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        currentSegmentChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = () => {
                    // Save this segment
                    if (currentSegmentChunks.length > 0) {
                        const segmentBlob = new Blob(currentSegmentChunks, { type: 'audio/webm' });
                        audioSegments.push(segmentBlob);
                        console.log(`‚úÖ Saved audio segment ${audioSegments.length}, size: ${segmentBlob.size} bytes`);
                    }
                    currentSegmentChunks = [];
                };

                mediaRecorder.start();
                isRecording = true;
                console.log('üé§ Started recording user audio segment');
            } catch (error) {
                console.error('Error starting audio recording:', error);
            }
        }

        // Stop recording user audio segment (when user stops speaking)
        function stopRecordingSegment() {
            if (mediaRecorder && isRecording && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                isRecording = false;
                console.log('üõë Stopped recording user audio segment');
            }
        }

        // Handle messages from Realtime API
        function handleMessage(message) {
            if (message.type === 'response.audio_transcript.delta' && message.delta) {
                messageText += message.delta;
                updateMessageText(messageText);
            } else if (message.type === 'response.audio_transcript.done') {
                // AI finished speaking
                if (messageText) {
                    removeStreamingAssistantMessage();
                    addMessage('assistant', messageText);
                    conversationHistory.push({ role: 'assistant', content: messageText });
                    
                    // Show countdown before listening
                    showCountdown(() => {
                        updateStatus('listening', 'üé§ Listening...');
                        // Start recording when we enter listening state (user will speak)
                        startRecordingSegment();
                    });
                    
                    messageText = '';
                }
            } else if (message.type === 'conversation.item.input_audio_transcription.started') {
                // User started speaking - ensure we're recording
                if (!isRecording) {
                    startRecordingSegment();
                }
            } else if (message.type === 'conversation.item.input_audio_transcription.completed') {
                // User finished speaking - stop recording this segment
                stopRecordingSegment();
                
                // User speech transcribed
                const transcript = message.transcript;
                if (transcript) {
                    addMessage('user', transcript);
                    conversationHistory.push({ role: 'user', content: transcript });
                    updateStatus('processing', 'ü§î AI is thinking...');
                }
            } else if (message.type === 'response.audio.delta') {
                updateStatus('speaking', 'üîä AI is speaking...');
                // Stop recording if AI starts speaking (in case user was still speaking)
                stopRecordingSegment();
            } else if (message.type === 'response.audio.done') {
                updateStatus('listening', 'üé§ Listening...');
                // Start recording when we enter listening state
                startRecordingSegment();
            }
        }

        // Remove streaming assistant message
        function removeStreamingAssistantMessage() {
            const messagesDiv = document.getElementById('messages');
            const messages = Array.from(messagesDiv.children);
            
            for (let i = messages.length - 1; i >= 0; i--) {
                const msg = messages[i];
                if (msg.classList.contains('assistant') && msg.hasAttribute('data-streaming')) {
                    msg.remove();
                    break;
                }
            }
        }
        
        // Update streaming message text
        function updateMessageText(text) {
            const messagesDiv = document.getElementById('messages');
            const messages = Array.from(messagesDiv.children);
            
            let streamingMessage = null;
            for (let i = messages.length - 1; i >= 0; i--) {
                const msg = messages[i];
                if (msg.classList.contains('assistant') && msg.hasAttribute('data-streaming')) {
                    streamingMessage = msg;
                    break;
                }
            }
            
            if (streamingMessage) {
                const textDiv = streamingMessage.querySelector('.message-text');
                if (textDiv) {
                    textDiv.textContent = text;
                }
            } else {
                const messageDiv = document.createElement('div');
                messageDiv.className = 'message assistant';
                messageDiv.setAttribute('data-streaming', 'true');
                
                const labelDiv = document.createElement('div');
                labelDiv.className = 'message-label';
                labelDiv.textContent = 'ü§ñ Assistant';
                
                const textDiv = document.createElement('div');
                textDiv.className = 'message-text';
                textDiv.textContent = text;
                
                messageDiv.appendChild(labelDiv);
                messageDiv.appendChild(textDiv);
                messagesDiv.appendChild(messageDiv);
            }
            
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }

        // Stop assessment and score
        async function stopAssessment() {
            if (dataChannel) {
                dataChannel.close();
                dataChannel = null;
            }

            if (peerConnection) {
                peerConnection.getSenders().forEach(sender => {
                    sender.track?.stop();
                });
                peerConnection.close();
                peerConnection = null;
            }

            if (audioElement) {
                audioElement.pause();
                audioElement.srcObject = null;
                audioElement.remove();
                audioElement = null;
            }

            // Stop any ongoing recording segment
            stopRecordingSegment();

            // Wait a bit for the last segment to finish saving
            await new Promise(resolve => setTimeout(resolve, 500));

            // Combine all audio segments into one continuous audio stream
            if (audioSegments.length > 0) {
                console.log(`üîó Combining ${audioSegments.length} audio segments...`);
                
                try {
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    
                    // Decode all segments to AudioBuffers
                    const audioBuffers = [];
                    for (let i = 0; i < audioSegments.length; i++) {
                        const arrayBuffer = await audioSegments[i].arrayBuffer();
                        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                        audioBuffers.push(audioBuffer);
                        console.log(`‚úÖ Decoded segment ${i + 1}/${audioSegments.length}, duration: ${audioBuffer.duration.toFixed(2)}s`);
                    }

                    // Combine all AudioBuffers into one continuous buffer
                    const sampleRate = audioBuffers[0].sampleRate;
                    const numberOfChannels = audioBuffers[0].numberOfChannels;
                    let totalLength = 0;
                    
                    // Calculate total length
                    audioBuffers.forEach(buffer => {
                        totalLength += buffer.length;
                    });

                    // Create combined buffer
                    const combinedBuffer = audioContext.createBuffer(numberOfChannels, totalLength, sampleRate);
                    
                    // Copy each buffer into the combined buffer
                    let offset = 0;
                    audioBuffers.forEach((buffer, index) => {
                        for (let channel = 0; channel < numberOfChannels; channel++) {
                            const channelData = combinedBuffer.getChannelData(channel);
                            const sourceData = buffer.getChannelData(channel);
                            channelData.set(sourceData, offset);
                        }
                        offset += buffer.length;
                        console.log(`  Copied segment ${index + 1}/${audioBuffers.length} (${buffer.length} samples) at offset ${offset - buffer.length}`);
                    });

                    console.log(`‚úÖ Combined ${audioSegments.length} segments into one buffer, total duration: ${combinedBuffer.duration.toFixed(2)}s`);

                    // Convert combined AudioBuffer to WAV
                    audioBlob = audioBufferToWav(combinedBuffer);
                    console.log(`‚úÖ Converted to WAV, size: ${audioBlob.size} bytes`);

                    // For debugging: play the combined audio
                    const audioUrl = URL.createObjectURL(audioBlob);
                    document.getElementById('audioPlayback').src = audioUrl;
                    document.getElementById('audioPlayer').style.display = 'block';
                } catch (error) {
                    console.error('Error combining/converting audio:', error);
                    // Fallback: try simple blob combination
                    audioBlob = new Blob(audioSegments, { type: 'audio/webm' });
                    const audioUrl = URL.createObjectURL(audioBlob);
                    document.getElementById('audioPlayback').src = audioUrl;
                    document.getElementById('audioPlayer').style.display = 'block';
                }
            } else {
                console.warn('‚ö†Ô∏è No audio segments recorded');
                audioBlob = null;
            }

            if (userAudioTrack) {
                userAudioTrack.stop();
                userAudioTrack = null;
            }

            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            document.getElementById('languageToggle').disabled = false;
            isSessionActive = false;
            messageText = '';

            // If we have conversation history, score it
            if (conversationHistory.length > 0) {
                await scoreAssessment();
            } else {
                updateStatus('idle', 'Assessment stopped');
            }

            // Run voice analysis if we have audio
            if (audioBlob) {
                await analyzeAudio();
            }
        }

        // Score assessment using OpenAI API
        async function scoreAssessment() {
            const apiKey = await getApiKey();
            if (!apiKey) {
                alert('API key needed for scoring');
                return;
            }

            updateStatus('scoring', 'üìä Scoring assessment...');
            document.getElementById('resultsSection').classList.add('active');
            document.getElementById('scoringSpinner').style.display = 'inline-block';
            document.getElementById('scoringStatus').textContent = 'Analyzing responses...';

            try {
                // Get today's date for scoring
                const todayDate = new Date().toLocaleDateString('en-US', { weekday: 'long', month: 'long', day: 'numeric', year: 'numeric' });
                
                const scoringPrompt = `You are scoring a TICS-m cognitive assessment. Analyze the conversation and provide scores for each question.

The conversation transcript:
${conversationHistory.map(msg => `${msg.role === 'user' ? 'User' : 'Assistant'}: ${msg.content}`).join('\n')}

Expected correct answers:
1. Today's date: Should match ${todayDate}
2. City: Singapore
3. Digits forward (8-1-4): Should be "8, 1, 4" or "814" or similar
4. Digits backward (6-2-9): Should be "9, 2, 6" backwards or "926" backwards or similar
5. Three words: Should include "river", "chair", and "mango"

Please provide a JSON response with this exact structure:
{
  "questions": [
    {
      "question": "What is today's date?",
      "category": "Orientation",
      "userAnswer": "[extracted answer]",
      "correct": true/false,
      "score": 1 or 0,
      "explanation": "Brief explanation of why correct/incorrect"
    },
    {
      "question": "What city are we in right now?",
      "category": "Orientation",
      "userAnswer": "[extracted answer]",
      "correct": true/false,
      "score": 1 or 0,
      "explanation": "Brief explanation"
    },
    {
      "question": "Repeat digits forward: 8-1-4",
      "category": "Attention",
      "userAnswer": "[extracted answer]",
      "correct": true/false,
      "score": 1 or 0,
      "explanation": "Brief explanation"
    },
    {
      "question": "Repeat digits backward: 6-2-9",
      "category": "Attention",
      "userAnswer": "[extracted answer]",
      "correct": true/false,
      "score": 1 or 0,
      "explanation": "Brief explanation"
    },
    {
      "question": "Repeat three words: river, chair, mango",
      "category": "Immediate Recall",
      "userAnswer": "[extracted answer]",
      "correct": true/false,
      "score": 1 or 0,
      "explanation": "Brief explanation. Note: all three words must be present for correct"
    }
  ],
  "summary": {
    "orientationScore": 0-2,
    "attentionScore": 0-2,
    "immediateRecallScore": 0-1,
    "totalScore": 0-5
  }
}

Return ONLY valid JSON, no other text.`;

                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: JSON.stringify({
                        model: 'gpt-4o',
                        messages: [
                            { role: 'system', content: 'You are a cognitive assessment scoring expert. Always return valid JSON only.' },
                            { role: 'user', content: scoringPrompt }
                        ],
                        temperature: 0.3,
                        response_format: { type: 'json_object' }
                    })
                });

                if (!response.ok) {
                    const error = await response.json();
                    throw new Error(error.error?.message || 'Scoring failed');
                }

                const data = await response.json();
                const scoreData = JSON.parse(data.choices[0].message.content);

                // Display results
                displayResults(scoreData);

                // Save to server
                await saveAssessmentResults(scoreData);

                document.getElementById('scoringSpinner').style.display = 'none';
                document.getElementById('scoringStatus').textContent = 'Assessment scored successfully!';
                updateStatus('idle', 'Assessment complete');

            } catch (error) {
                console.error('Error scoring assessment:', error);
                document.getElementById('scoringSpinner').style.display = 'none';
                document.getElementById('scoringStatus').textContent = `Error: ${error.message}`;
                updateStatus('error', `Scoring error: ${error.message}`);
            }
        }

        // Display results
        function displayResults(scoreData) {
            const summaryStats = document.getElementById('summaryStats');
            const summary = scoreData.summary;
            
            summaryStats.innerHTML = `
                <div class="summary-stat">
                    <div class="summary-stat-label">Orientation</div>
                    <div class="summary-stat-value">${summary.orientationScore}/2</div>
                </div>
                <div class="summary-stat">
                    <div class="summary-stat-label">Attention</div>
                    <div class="summary-stat-value">${summary.attentionScore}/2</div>
                </div>
                <div class="summary-stat">
                    <div class="summary-stat-label">Immediate Recall</div>
                    <div class="summary-stat-value">${summary.immediateRecallScore}/1</div>
                </div>
                <div class="summary-stat">
                    <div class="summary-stat-label">Total Score</div>
                    <div class="summary-stat-value">${summary.totalScore}/5</div>
                </div>
            `;

            const scoreCards = document.getElementById('scoreCards');
            scoreCards.innerHTML = '';

            scoreData.questions.forEach((q, index) => {
                const card = document.createElement('div');
                card.className = 'score-card';
                
                const badgeClass = q.correct ? 'correct' : 'incorrect';
                const badgeText = q.correct ? '‚úì Correct' : '‚úó Incorrect';
                
                card.innerHTML = `
                    <div class="score-card-header" onclick="toggleExplanation(${index})">
                        <h3>${q.question}</h3>
                        <span class="score-badge ${badgeClass}">${badgeText}</span>
                    </div>
                    <div class="score-explanation" id="explanation-${index}">
                        <div class="score-explanation-content">
                            <p><strong>Your answer:</strong> ${q.userAnswer || 'No answer recorded'}</p>
                            <p><strong>Explanation:</strong> ${q.explanation}</p>
                        </div>
                    </div>
                `;
                
                scoreCards.appendChild(card);
            });
        }

        // Toggle explanation
        function toggleExplanation(index) {
            const explanation = document.getElementById(`explanation-${index}`);
            explanation.classList.toggle('expanded');
        }

        // Save assessment results
        async function saveAssessmentResults(scoreData) {
            const now = new Date();
            const record = {
                type: 'tics_assessment',
                dateTime: now.toISOString(),
                date: now.toISOString().split('T')[0],
                time: now.toTimeString().split(' ')[0],
                scores: scoreData.summary,
                questions: scoreData.questions,
                conversationHistory: conversationHistory,
                completed: true
            };

            try {
                const response = await fetch('/api/assessments', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(record)
                });
                if (response.ok) {
                    console.log('‚úÖ Assessment results saved:', record);
                } else {
                    console.error('Failed to save assessment results');
                }
            } catch (error) {
                console.error('Error saving assessment results:', error);
            }
        }

        // Add message to UI
        function addMessage(role, text) {
            const messagesDiv = document.getElementById('messages');
            
            if (messagesDiv.children.length === 1 && messagesDiv.children[0].textContent.includes('Assessment')) {
                messagesDiv.innerHTML = '';
            }

            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;
            
            const labelDiv = document.createElement('div');
            labelDiv.className = 'message-label';
            labelDiv.textContent = role === 'user' ? 'üë§ You' : role === 'assistant' ? 'ü§ñ Assistant' : '‚ÑπÔ∏è System';
            
            const textDiv = document.createElement('div');
            textDiv.className = 'message-text';
            textDiv.textContent = text;
            
            messageDiv.appendChild(labelDiv);
            messageDiv.appendChild(textDiv);
            messagesDiv.appendChild(messageDiv);
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }

        // Clear messages
        function clearMessages() {
            document.getElementById('messages').innerHTML = '';
        }

        // Update status
        function updateStatus(type, message) {
            const statusDiv = document.getElementById('status');
            statusDiv.className = `status ${type}`;
            statusDiv.textContent = message;
            
            if (type === 'listening') {
                statusDiv.classList.add('pulse');
            } else {
                statusDiv.classList.remove('pulse');
            }
        }

        // Toggle language between English and Chinese
        function toggleLanguage() {
            currentLanguage = currentLanguage === 'en' ? 'zh' : 'en';
            const languageLabel = document.getElementById('languageLabel');
            const languageFlag = document.getElementById('languageFlag');
            
            if (currentLanguage === 'zh') {
                languageLabel.textContent = '‰∏≠Êñá';
                languageFlag.textContent = 'üá®üá≥';
            } else {
                languageLabel.textContent = 'English';
                languageFlag.textContent = 'üá∫üá∏';
            }
        }

        // Normalize prediction labels (CTRL -> Healthy, etc.)
        function normalizePrediction(pred) {
            const predStr = String(pred).toUpperCase().trim();
            if (predStr === 'CTRL' || predStr === 'CONTROL' || predStr === 'HEALTHY') {
                return 'Healthy';
            } else if (predStr === 'MCI' || predStr.includes('MCI')) {
                return 'MCI';
            }
            return pred; // Return original if not recognized
        }

        // Convert AudioBuffer to WAV Blob
        function audioBufferToWav(buffer) {
            const numChannels = buffer.numberOfChannels;
            const sampleRate = buffer.sampleRate;
            const format = 1; // PCM
            const bitDepth = 16;
            
            const bytesPerSample = bitDepth / 8;
            const blockAlign = numChannels * bytesPerSample;
            
            const length = buffer.length * numChannels * bytesPerSample + 44;
            const arrayBuffer = new ArrayBuffer(length);
            const view = new DataView(arrayBuffer);
            const samples = [];
            
            // Convert float samples to 16-bit PCM
            for (let channel = 0; channel < numChannels; channel++) {
                const channelData = buffer.getChannelData(channel);
                for (let i = 0; i < channelData.length; i++) {
                    const sample = Math.max(-1, Math.min(1, channelData[i]));
                    samples.push(sample < 0 ? sample * 0x8000 : sample * 0x7FFF);
                }
            }
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, length - 8, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, format, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * blockAlign, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, bitDepth, true);
            writeString(36, 'data');
            view.setUint32(40, length - 44, true);
            
            // Write samples
            let offset = 44;
            for (let i = 0; i < samples.length; i++) {
                view.setInt16(offset, samples[i], true);
                offset += 2;
            }
            
            return new Blob([arrayBuffer], { type: 'audio/wav' });
        }

        async function analyzeAudio() {
            try {
                // Step 1: Analyze voice features (if audio available)
                if (!audioBlob) {
                    console.warn('No audio blob available for voice analysis');
                    return;
                }

                updateStatus('processing', 'üîÑ Analyzing voice features...');

                // Convert blob to File for FormData
                const audioFile = new File([audioBlob], 'recording.wav', { type: 'audio/wav' });
                const formData = new FormData();
                formData.append('audio', audioFile);

                const response = await fetch(API_ENDPOINT, {
                    method: 'POST',
                    body: formData
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`Server error: ${response.status} - ${errorText}`);
                }

                const result = await response.json();
                
                // Display results
                const prediction = result.prediction || result.pred || 'Unknown';
                const normalizedPrediction = normalizePrediction(prediction);
                
                const predictedClassDiv = document.getElementById('predictedClass');
                predictedClassDiv.innerHTML = '';
                
                // Add icon
                const icon = document.createElement('span');
                icon.className = `result-icon ${normalizedPrediction.toLowerCase()}`;
                icon.textContent = normalizedPrediction === 'Healthy' ? '‚úÖ' : '‚ö†Ô∏è';
                predictedClassDiv.appendChild(icon);
                
                // Add text
                const text = document.createElement('span');
                text.textContent = normalizedPrediction;
                predictedClassDiv.appendChild(text);
                
                // Show description modal
                const descriptionModal = document.getElementById('descriptionModal');
                const descriptionTitle = document.getElementById('descriptionTitle');
                const descriptionText = document.getElementById('descriptionText');
                
                if (normalizedPrediction === 'Healthy') {
                    descriptionTitle.textContent = '‚úÖ Healthy Cognitive Status';
                    descriptionText.textContent = 'Your voice analysis indicates healthy cognitive function. This is a positive result, but please remember this is a screening tool and not a medical diagnosis.';
                    descriptionModal.style.display = 'block';
                } else if (normalizedPrediction === 'MCI') {
                    descriptionTitle.textContent = '‚ö†Ô∏è Mild Cognitive Impairment (MCI)';
                    descriptionText.textContent = 'Your voice analysis suggests possible mild cognitive impairment. This is a screening result and should be discussed with a healthcare professional for proper evaluation.';
                    descriptionModal.style.display = 'block';
                } else {
                    descriptionModal.style.display = 'none';
                }
                
                // Display probabilities as horizontal bar chart
                if (result.probabilities) {
                    const probSection = document.getElementById('probabilitiesSection');
                    const probContainer = document.getElementById('probabilities');
                    probContainer.innerHTML = '';
                    
                    // Sort probabilities by value (highest first)
                    const sortedProbs = Object.entries(result.probabilities)
                        .sort((a, b) => b[1] - a[1]);
                    
                    sortedProbs.forEach(([label, value]) => {
                        const normalizedLabel = normalizePrediction(label);
                        const percentage = (value * 100).toFixed(1);
                        const barClass = normalizedLabel.toLowerCase();
                        
                        const probContainerItem = document.createElement('div');
                        probContainerItem.className = 'probability-bar-container';
                        probContainerItem.innerHTML = `
                            <div class="probability-bar-label">
                                <span>${normalizedLabel}</span>
                                <span>${percentage}%</span>
                            </div>
                            <div class="probability-bar-wrapper">
                                <div class="probability-bar ${barClass}" style="width: 0%;" data-width="${percentage}">
                                    ${percentage}%
                                </div>
                            </div>
                        `;
                        probContainer.appendChild(probContainerItem);
                    });
                    
                    // Animate bars after a short delay
                    setTimeout(() => {
                        const bars = probContainer.querySelectorAll('.probability-bar');
                        bars.forEach(bar => {
                            const width = bar.getAttribute('data-width');
                            bar.style.width = width + '%';
                        });
                    }, 100);
                    
                    probSection.style.display = 'block';
                } else {
                    document.getElementById('probabilitiesSection').style.display = 'none';
                }

                document.getElementById('voiceAnalysisResults').classList.add('active');
                console.log('‚úÖ Voice analysis complete');
                
                // Update scoring status to show completion
                document.getElementById('scoringSpinner').style.display = 'none';
                document.getElementById('scoringStatus').textContent = '‚úÖ Assessment and voice analysis complete!';
            } catch (error) {
                console.error('Error analyzing audio:', error);
                alert('Error analyzing audio: ' + error.message);
                
                // Update scoring status even on error
                document.getElementById('scoringSpinner').style.display = 'none';
                document.getElementById('scoringStatus').textContent = '‚ö†Ô∏è Assessment complete, but voice analysis failed.';
            }
        }

        // Initialize on page load
        window.addEventListener('load', async () => {
            const urlParams = new URLSearchParams(window.location.search);
            const keyParam = urlParams.get('key');
            if (keyParam) {
                document.getElementById('apiKey').value = keyParam;
            } else {
                try {
                    const response = await fetch('/api-key');
                    if (response.ok) {
                        const data = await response.json();
                        if (data.apiKey) {
                            document.getElementById('apiKey').value = data.apiKey;
                        }
                    }
                } catch (e) {
                    console.log('Running standalone - enter API key manually');
                }
            }
        });
    </script>
</body>
</html>

